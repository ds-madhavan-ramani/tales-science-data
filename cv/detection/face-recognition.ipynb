{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "    /* DOWNLOAD COMPUTER MODERN FONT JUST IN CASE */\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "\n",
       "    /* GLOBAL TEXT FONT */\n",
       "    div#notebook,\n",
       "    div.output_area pre,\n",
       "    div.output_wrapper,\n",
       "    div.prompt {\n",
       "      font-family: Times new Roman, monospace !important;\n",
       "    }\n",
       "\n",
       "    /* CENTER FIGURE */\n",
       "    .output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    /* LINK */\n",
       "    a {\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H1 */\n",
       "    h1 {\n",
       "        font-size: 42px !important;\n",
       "        text-align: center;\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h2 {\n",
       "        font-size: 32px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h3 {\n",
       "        font-size: 24px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h4 {\n",
       "        font-size: 20px !important;\n",
       "    }\n",
       "\n",
       "    /* PARAGRAPH */\n",
       "    p {\n",
       "        font-size: 16px !important;\n",
       "        text-align: center;\n",
       "    }\n",
       "\n",
       "    /* LIST ITEM */\n",
       "    li {\n",
       "        font-size: 16px !important;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../../common/import_all.py\n",
    "\n",
    "from common.setup_notebook import set_css_style, setup_matplotlib, config_ipython\n",
    "config_ipython()\n",
    "setup_matplotlib()\n",
    "set_css_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we mean\n",
    "\n",
    "We describe here the procedure to recognise faces in images as \"similar\". We are *not* talking about face detection, which is the task of finding faces in an image. \n",
    "\n",
    "As humans, recognising a person by his/her face is a very quick task, mundane even for our daily life, although the specifics of what happens in the human brain are still to be fully understood. This [[article]](#sciam) narrates a recent breakthrough (at the time of writing this at least) on the topic.\n",
    "\n",
    "As machines though, the situation is different. There have been approaches based on vectors built with geometrical features [[1]](#kanade), but they have been proven to not be good enough. Standard methods today consist in training a Machine Learning classifier (we are not considering recent Deep Learning approaches here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenfaces\n",
    "\n",
    "The *eigenfaces* (yes, they are really called like that) are the set of eigenvectors outlining the major properties of a face and derived via PCA and used to train a classifier. [Wikipedia](https://en.wikipedia.org/wiki/Eigenface) has a good page on the topic.\n",
    "\n",
    "An image is a high-dimensional object and not all the features which can be inferred from its pixels are relevant. The steps of the algorithm computing the eigenfaces are:\n",
    "\n",
    "1. Use a large training set of images of faces, ideally taken under the same light conditions;\n",
    "2. Normalise them in such a way to have eyes and mouth aligned and then resampled to the same pixel resolution;\n",
    "2. Perform a PCA and project the original images onto the chosen components;\n",
    "3. The query image is then projected on the principal components as well;\n",
    "4. Use a distance method to compare the projected query image and the projected training images\n",
    "\n",
    "The problem with computing the PCA on many large images is about performance. With 400 $10^2 \\times 10^2$ images, the covariance matrix will be $10^4 \\times 10^4$. Thankfully though, note that a $M \\times N$ matrix with $M > N$ has only $N-1$ non-zero eigenvalues, so the problem becomes much more accessible.\n",
    "\n",
    "In fact what we can do is apply this little small trick. Instead of the eigenvalues and eigenvectors of $XX^T$, where  $X$ is the dataset matrix,  which is a $M \\times M$ matrix, we can use the eigenvalues and eigenvectors of $X^TX$, which is a  $N \\times N$ matrix, much smaller. Because matrix multiplication is associative, this gives:\n",
    "\n",
    "\\begin{align*}\n",
    " \t(X^TX) \\mathbf{v} &= \\lambda \\mathbf{v} \\\\\n",
    " \tX(X^TX) \\mathbf{v} &=  \\lambda  X \\mathbf{v} \\\\\n",
    " \t(XX^T)(X \\mathbf{v}) &=  \\lambda  (X \\mathbf{v})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisherfaces\n",
    "\n",
    "A PCA in the eigenfaces approach finds linear combinations of features that maximise the total variance in the data. This way, some discriminative information can be lost when throwing away the components which do not contribute much to the variance. This is particularly a problem when variance is generated by an external source in the images, like light and this is why that approach works well only when images are taken in the same conditions.\n",
    "\n",
    "The Fisherface approach is a sort of correction on this problem which uses a Linear Discriminant Analysis, which allows for class-specific dimensionality reduction. See this nice page on [Scholarpedia](http://www.scholarpedia.org/article/Fisherfaces)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBPH: Local Binary Patterns Histograms\n",
    "\n",
    "Both the Eigenfaces and the Fisherfaces approaches require to be trained on several images per person.\n",
    "\n",
    "LBPH, standing for *Local Binary Pattern Histograms*, [[3]](#3) is a 2-dimensional texture analysis method which consists in comparing each pixel with its neighbourhood. \n",
    "\n",
    "<img src=\"../../imgs/lbph-pixels.jpg\" align=\"left\" width=\"300\" style=\"margin:0px 50px\"/>\n",
    "\n",
    "Consider the situation illustrated in the figure here: the image is transformed into a matrix of binary numbers, so that $2^8$ combinations are possible, given that in 2 dimensions each pixel has 8 neighbours. Here is where *binary* in the name of the method comes from. A pixel and its neighbourhood are depicted: if the neigbouring pixel has higher intensity, it gets a 1, otherwise it gets a 0.\n",
    "\n",
    "The LBP operator is defined as, in a generic $p$-dimensional space,\n",
    "\n",
    "$$\n",
    "LBP(x_c, y_c) = \\sum_{k=0}^{k=p-1} 2^k S(i_p-i_c) \\ ,\n",
    "$$\n",
    "\n",
    "where $i$ indicates the pixel's [intensity](../some-glossary.ipynb#Intensity), $(x_c, y_c)$ is the central pixel under consideration and  $S(x)$  is the sign function:\n",
    "\n",
    "$$\n",
    "S(x) =\n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t1  & \\mbox{if } x \\geq 0 \\\\\n",
    "\t\t0 & \\mbox{if } x < 0\n",
    "\t\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "This method captures fine-grained details. However, a fixed neighbourhood cannot encode details which differ in scale, so the operator has been modified to account for a variable neighborhood [[4]](#4) so that an arbitrary number of pixels is aligned on a circle with variable radius to capture the neighbourhoods (see figure).\n",
    "\n",
    "<img src=\"../../imgs/lbph-circle.jpg\" width=\"500\"/>\n",
    "\n",
    "For a given point $(x_c, y_c)$, the neighbour $(x_p, y_p)$, with $p \\in D$ ($D$ being the number of dimensions), can be calculated as\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "x_p = x_c + R \\cos(\\frac{2 \\pi p}{D}) \\\\\n",
    "y_p = y_c - R \\sin(\\frac{2 \\pi p}{D})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The operator is an extension of the LBP one. If a point on the circle does not correspond to the image coordinate, it gets interpolated.\n",
    "\n",
    "The recognition of faces works by dividing the LBP image in local regions and extracting a histogram from each region. The local histograms, concatenated, give a spatially enhanced feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. <a name=\"sciam\"></a> [How we save face -- Researchers crack the brain's facial recognition code](https://www.scientificamerican.com/article/how-we-save-face-researchers-crack-the-brains-facial-recognition-code/), *Scientific American*, 1 June 2017\n",
    "2. <a name=\"kanade\"></a> T Kanade, [*Picture processing system by computer complex and recognition of human faces*](http://www.ri.cmu.edu/pub_files/pub3/kanade_takeo_1973_1/kanade_takeo_1973_1.pdf), Doctoral Thesis, Kyoto University, 1973\n",
    "3. <a name=\"3\"></a> T Ojala, M Pietikainen, D Harwood, [Performance evaluation of texture measures with classification based on Kullback discrimination of distributions](http://ieeexplore.ieee.org/abstract/document/576366/), *Pattern Recognition, Proceedings of the 12th IAPR International Conference, IEEE*, 1, 1994\n",
    "4. <a></a> T Ahonen, A Hadid, M Pietikainen, [Face description with local binary patterns: Application to face recognition](https://pdfs.semanticscholar.org/7476/922f1f6b69d9425b013613442bd4ee099fbe.pdf), *IEEE transactions on pattern analysis and machine intelligence*, 28:12, 2006\n",
    "4. <a name=\"4\"></a> [A very well done and detailed explanation of the three methods and usage in OpenCV](http://eyalarubas.com/face-detection-and-recognition.html)\n",
    "5. <a name=\"5\"></a> Y S Liu W S Ng C W Liu, [A comparison of different face recognition algorithms](http://cs.unc.edu/~chunwei/papers/2009pr_face_recog.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
